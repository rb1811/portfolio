[
  {
    "title": "Personal Portfolio",
    "teamsize": 1,
    "short_description": "This website is a fully functional, static web portfolio developed end-to-end using only *Python* and the *Reflex* framework. Having your own portfolio website to showcase your coding skills adds a different touch. Also why pay money to resume builder website, when you can make your own?",
    "full_description": [
      "Developed to showcase execution ability, leveraging a Python-centric skillset for a full-stack result.",
      "Achieved end-to-end web development using the Reflex framework (Python-only), eliminating traditional front-end technologies (HTML/CSS/JS).",
      "Successfully utilized Large Language Models (LLMs) to rapidly acquire and implement necessary UI/UX principles, compensating for limited prior front-end experience.",
      "Demonstrates rapid prototyping, efficient UI development, and AI-assisted skill acquisition, showcasing technical tenacity."
    ],
    "languages_used": ["Python", "Docker", "Reflex"],
    "href": "https://github.com/rb1811/portfolio"
  },
  {
    "title": "Berkeley's PACMAN",
    "teamsize": 1,
    "short_description": "AI implementation project based on the University of Berkeley's *Pacman* environment, focused on foundational search algorithms.",
    "full_description": [
      "To foster hands-on learning of AI principles, the University of Berkeley has made its PAC-MAN project open source for adoption by other educational institutions.",
      "Implemented fundamental AI algorithms within the *University of Berkeley's open-source Pacman project environment*.",
      "Integrated and trained agents using classical search strategies Breadth-First Search (BFS), Depth-First Search (DFS).",
      "Applied advanced techniques including *Reinforcement Learning* to enable agents to master the game.",
      "Served as a practical application and demonstration of core AI concepts in a popular environment."
    ],
    "languages_used": ["Python"],
    "href": "https://github.com/rb1811/Pacman",
    "extra_href": "https://inst.eecs.berkeley.edu/~cs188/fa24/projects/",
    "extra_href_display_name": "Berkeley Project Course Page"
  },
  {
    "title": "GitHub Trending Visualizer",
    "teamsize": 1,
    "short_description": "A web-based tool for data visualization of daily trending open-source projects on GitHub.",
    "full_description": [
      "Engineered a full-stack data pipeline to *crawl* and *visualize* daily trending open-source projects from GitHub.",
      "Developed *Python crawlers* using *Scrapy* and *BeautifulSoup* to extract key metrics (forks, languages, companies).",
      "Utilized a *Flask* backend to serve the processed data to the client.",
      "Employed the *D3.js* JavaScript library for dynamic, web-based visualization on the frontend."
    ],
    "languages_used": ["Python", "Flask", "Scrapy", "D3.JS", "JavaScript", "beautifulsoup"],
    "href": "https://github.com/rb1811/githubtrending"
  },
  {
    "title": "Network Planning Management Tool (NPMT)",
    "teamsize": 3,
    "short_description": "Code implementation of a network optimization research paper, focused on identifying critical network nodes for maximum disruption.",
    "full_description": [
      "Developed a functional tool based on a research paper regarding *Network Planning Management* and optimization.",
      "Modeled a large-scale graph network (e.g., commercial flight routes) for analysis.",
      "Implemented the paper's complex algorithm to determine the *minimum set of critical nodes* necessary to disrupt the entire network.",
      "Demonstrates the ability to translate complex theoretical algorithms into robust, executable *Python* code."
    ],
    "languages_used": ["Python"],
    "href": "https://github.com/rb1811/NPMT"
  },
  {
    "title": "American Sign Language Recognition",
    "teamsize": 1,
    "short_description": "A machine learning project for *American Sign Language (ASL)* translation, converting gestures to text.",
    "full_description": [
      "High-impact ASU research project to develop a *User-Dependent and User-Independent ASL recognition system*.",
      "Implemented a full workflow: *data collection (via sensors)*, processing, gesture annotation, and *feature extraction* (*FFT* and *DWT*).",
      "Employed *Feature Selection* using *PCA* to optimize the model training process.",
      "Trained machine learning models (*Decision Trees, SVM, Keras-based Feed Forward Neural Networks*) to accurately classify 10 core ASL words, contributing to communication research."
    ],
    "languages_used": ["Matlab", "Python", "Data Mining"],
    "href": "https://github.com/rb1811/American-Sign-Language-Recognition"
  },
  {
    "title": "Benes Network Visualization and Analysis",
    "teamsize": 3,
    "short_description": "A *Python-based visualization* and computation tool demonstrating the efficiency of calculating indices on a *Benes Network*.",
    "full_description": [
      "Developed a *Python/Pygame* application to visualize and analyze network topology related to a published research paper.",
      "Calculates the *Transmission Index* and *Wiener Index* on a *Benes Network*.",
      "Demonstrates a novel method that achieves a significant reduction in time complexity (to linear or constant time) for index calculation.",
      "Includes logic to procedurally *generate a diamond-shaped Benes Network* of N dimensions for analysis."
    ],
    "extra_href": "https://www.researchgate.net/publication/389045573_Transmission_in_Benes_Network",
    "languages_used": ["Python","Pygame"],
    "href": "https://github.com/rb1811/benes-graphics",
    "extra_href_display_name": "Research Paper"
  },
  {
    "title": "Social Media Web Crawlers",
    "teamsize": 1,
    "short_description": "Developed *web crawlers (bots)* to extract research data from various social media and review platforms for an ASU Data Mining lab.",
    "full_description": [
      "Worked as a part-time developer for a *Data Mining research lab* during Master's program.",
      "Primary responsibility was designing and deploying specialized *Python web crawlers*.",
      "Utilized *Scrapy* and *BeautifulSoup* to reliably extract data from various social media and review platforms (Goodreads, Twitter, Youtube, Zomato).",
      "Data collected was used for subsequent academic analysis and research."
    ],
    "languages_used": ["Python", "Scrapy", "beautifulsoup"],
    "href": "https://github.com/rb1811/Social-Media-web-crawlers"
  },
  {
    "title": "Attacks on RSA Algorithm",
    "teamsize": 2,
    "short_description": "Implementation of several well-known and theoretical attacks to demonstrate vulnerabilities in the *RSA Cryptography Algorithm*.",
    "full_description": [
      "Implemented multiple famous and theoretical attacks against the *RSA encryption algorithm* from scratch in *C++*.",
      "The project's goal was to deeply understand the security foundations of the RSA algorithm.",
      "Demonstrated how various mathematical and theoretical weaknesses could be exploited to compromise the cryptographic system."
    ],
    "languages_used": ["C++"],
    "href": "https://github.com/rb1811/RSA-and-its-attacks"
  },
  {
    "title": "2D Map Generation Robot",
    "teamsize": 2,
    "image": "final_year_project.jpg",
    "short_description": "Developed a *Raspberry Pi-controlled robot* utilizing sonar sensors to autonomously generate a *2D floor map* for my final year Internet Of Things (IOT) themed project in under grad. ",
    "full_description": [
      "Designed and built a *four-wheeled miniature robot prototype* controlled by a *Raspberry Pi* chip.",
      "Motion was managed remotely via a laptop interface.",
      "Integrated *sonar sensors* to gather distance data, processed in real-time using *Python*.",
      "Constructed a *2D occupancy map* of the environment, targeting mapping applications in hazardous or inaccessible environments."
    ],
    "languages_used": ["Python"],
    "href": "https://github.com/rb1811/2D_Mapgen_Bot"
  },
  {
    "title": "Indian Missing Person",
    "teamsize": 2,
    "short_description": "Undergraduate Capstone Project: A web-based platform for reporting, tracking, and managing records of missing persons in India.",
    "full_description": [
      "This Project that earned the **'Best Project Award'** in the final year with a cash prize.",
      "Developed a comprehensive *web platform* for reporting, management, and *tracking of missing persons* across India.",
      "Utilized *Python* for core backend logic and *Neo4J* for efficient, relationship-based data storage.",
      "Designed to facilitate secure and reliable record management."
    ],
    "languages_used": ["Python", "Neo4J", "Php"],
    "href": "https://github.com/rb1811/Indian-Missing-Person"
  }
]